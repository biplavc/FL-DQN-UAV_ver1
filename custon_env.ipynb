{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9d248ad1115f2a4453f7a37f0dff78ab414b74708540b64a7ed5b44c60bd298d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow==2.3.0\n",
      "  Downloading tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 320.4 MB 13 kB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.12.0)\n",
      "Collecting keras-preprocessing<1.2,>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 12.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.11.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow==2.3.0) (3.13.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/biplav/.local/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.4.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow==2.3.0) (0.33.6)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow==2.3.0) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow==2.3.0) (3.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow==2.3.0) (0.1.8)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.17.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow==2.3.0) (1.25.0)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 15.3 MB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Using cached tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "Requirement already satisfied: setuptools in /home/biplav/anaconda3/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow==2.3.0) (45.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.22.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 12.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.16.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.7.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 12.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /home/biplav/anaconda3/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/biplav/anaconda3/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/biplav/anaconda3/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
      "Installing collected packages: keras-preprocessing, h5py, astunparse, gast, tensorboard-plugin-wit, tensorboard-data-server, tensorboard, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.0\n",
      "    Uninstalling Keras-Preprocessing-1.1.0:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.9.0\n",
      "    Uninstalling h5py-2.9.0:\n",
      "      Successfully uninstalled h5py-2.9.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.13.1\n",
      "    Uninstalling tensorboard-1.13.1:\n",
      "      Successfully uninstalled tensorboard-1.13.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 1.13.0\n",
      "    Uninstalling tensorflow-estimator-1.13.0:\n",
      "      Successfully uninstalled tensorflow-estimator-1.13.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 1.13.2\n",
      "    Uninstalling tensorflow-1.13.2:\n",
      "      Successfully uninstalled tensorflow-1.13.2\n",
      "Successfully installed astunparse-1.6.3 gast-0.3.3 h5py-2.10.0 keras-preprocessing-1.1.2 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.3.0 tensorflow-estimator-2.3.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/biplav/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: gym in /home/biplav/anaconda3/lib/python3.7/site-packages (0.10.11)\n",
      "Requirement already satisfied: six in /home/biplav/anaconda3/lib/python3.7/site-packages (from gym) (1.12.0)\n",
      "Requirement already satisfied: requests>=2.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from gym) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/biplav/anaconda3/lib/python3.7/site-packages (from gym) (1.17.2)\n",
      "Requirement already satisfied: scipy in /home/biplav/.local/lib/python3.7/site-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in /home/biplav/.local/lib/python3.7/site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests>=2.0->gym) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests>=2.0->gym) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests>=2.0->gym) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests>=2.0->gym) (3.0.4)\n",
      "Requirement already satisfied: future in /home/biplav/anaconda3/lib/python3.7/site-packages (from pyglet>=1.2.0->gym) (0.18.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/biplav/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: keras in /home/biplav/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/biplav/anaconda3/lib/python3.7/site-packages (from keras) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/biplav/anaconda3/lib/python3.7/site-packages (from keras) (1.17.2)\n",
      "Requirement already satisfied: pyyaml in /home/biplav/anaconda3/lib/python3.7/site-packages (from keras) (5.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/biplav/anaconda3/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/biplav/.local/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in /home/biplav/anaconda3/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/biplav/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting keras-rl2\n",
      "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 76 kB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow in /home/biplav/anaconda3/lib/python3.7/site-packages (from keras-rl2) (2.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (0.3.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (3.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (0.8.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (0.1.8)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (3.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (2.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (0.33.6)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/biplav/.local/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.4.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.25.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (2.10.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.17.2)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (2.7.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.11.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorflow->keras-rl2) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/biplav/anaconda3/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow->keras-rl2) (45.2.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.16.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.22.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/biplav/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.7.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.3.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2019.9.11)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/biplav/anaconda3/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.2.7)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /home/biplav/anaconda3/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/biplav/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/biplav/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.8)\n",
      "Installing collected packages: keras-rl2\n",
      "Successfully installed keras-rl2-1.0.5\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/biplav/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.3.0\n",
    "!pip install gym\n",
    "!pip install keras\n",
    "!pip install keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random\n",
    "import functools\n",
    "import operator\n",
    "from itertools import combinations\n",
    "from itertools import product \n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "UAV_capacity = 1\n",
    "BS_capacity = 1\n",
    "verbose = True\n",
    "action_size = 1 # just placeholder, actually will be calculated later\n",
    "MAX_STEPS = 5\n",
    "\n",
    "class UAV_network(Env):   # network of UAVs not just a single one\n",
    "    \n",
    "    def __init__(self, n_users, coverage, name, folder_name, packet_update_loss, packet_sample_loss, periodicity): # number of total user and the user-coverage for every UAV\n",
    "        \n",
    "        '''\n",
    "        param n_users        : int, no of users.\n",
    "        param n_UAVs         : int, number of UAVs in this scenario.\n",
    "        param coverage       : list of lists, each list has users covered by the drone indicated by the index of the sublist.\n",
    "        param user_list      : list, user list of all users.\n",
    "        param UAV_list       : list, generic UAV list. e.g. for 2 UAV [1, 2].\n",
    "        param users_UAVs     : dict, will contain the users covered by each jth UAV at jth index. user_UAVs[j+1] = self.coverage[j].\n",
    "        param act_coverage   : dict, same as users_UAVs but 0s removed. actual coverage.\n",
    "        param BW             : int, bandwidth.\n",
    "        param UAV_capacity   : int, number of users UAV can support in the uplink.\n",
    "        param BS_capacity    : int, number of UAVs BS can support in the backhaul.\n",
    "        user_locs            : list, locations of the users.\n",
    "        grid                 : list, grid points where the UAVs can be deployed.\n",
    "        UAV_loc              : list, UAV deployment positions.\n",
    "        cover                : list of list, list of list containing users covered by the drone in the index position.\n",
    "        UAV_age              : dict, age at UAV.\n",
    "        BS_age               : dict, age at BS.\n",
    "        BS_age_prev          : dict, age at BS in the previous step.\n",
    "        state                : list, state of the system - contains all ages at BS and UAV.\n",
    "        agent                : Object class, the DL agent that will be shared among all the UAVs.\n",
    "        actions              : list, possible actions.\n",
    "        action_size          : int, number of possible actions.\n",
    "        current_step         : step of the ongoing episode\n",
    "        episode_step         : int, current step of the ongoing episode. One episode gets over after MAX_STEP number of steps. Note difference with current_step\n",
    "        preference           : dict, at each index indicated by action is an array and the array has episode wise count of how many times the action was selected. Analogous to visualizing the q-table.\n",
    "        name                 : string, distinguish between eval and train networks.\n",
    "        age_dist_UAV         : dict, stores the episode ending age at UAV per user.\n",
    "        age_dist_BS          : dict, stores the episode ending age at BS per user.\n",
    "        tx_attempt_BS        : dict, at each index indicated by user is an array and the array has episode wise count of how many times the user was updated.\n",
    "        tx_attempt_UAV       : dict, at each index indicated by user is an array and the array has episode wise count of how many times the user was sampled.\n",
    "        \n",
    "        attempt_sample       : list, index is the episode and the value is the number of times a sample attempt was made. since each sampling results in 1 packet, this value is the number of users selected to sample\n",
    "        success_sample       : list, index is episode and value is the number of sampling attempts that were successful\n",
    "        \n",
    "        attempt_update       : list, index is the episode and the value is the number of times a sample attempt was made. since each sampling results in 1 packet, this value is the number of users selected to sample\n",
    "        success_update       : list, index is episode and value is the number of sampling attempts that were successful\n",
    "        sample_time          : dict, stores the slot at which an user was sampled. To show DQN samples at periods\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.n_users        = n_users\n",
    "        self.periodicity    = periodicity\n",
    "        self.coverage       = coverage\n",
    "        self.n_UAVs         = len(coverage)\n",
    "        self.UAV_capacity   = UAV_capacity\n",
    "        self.BS_capacity    = BS_capacity\n",
    "        self.users_UAVs     = {} # [i for i in range(1, self.n_users + 1)] # updated in start_network()\n",
    "        self.act_coverage   = {} # updated in start_network()\n",
    "        self.user_locs      = []\n",
    "        self.grid           = []\n",
    "        self.UAV_loc        = []\n",
    "        self.cover          = []\n",
    "        self.actions_space  = [] # initialized once the coverage is calculated\n",
    "        self.action_size    = 1 # will be updated in start_network()\n",
    "        self.episode_step   = 0\n",
    "        self.preference     = {}\n",
    "        self.current_step   = 1\n",
    "        self.UAV_age        = {}\n",
    "        self.BS_age         = {}\n",
    "        self.BS_age_prev    = {}\n",
    "        self.name           = name\n",
    "        self.age_dist_UAV   = {}\n",
    "        self.age_dist_BS    = {}    \n",
    "        self.tx_attempt_BS  = {}\n",
    "        self.tx_attempt_UAV = {}\n",
    "        self.user_list      = []\n",
    "        self.UAV_list       = []\n",
    "        self.folder_name    = folder_name\n",
    "        self.update_loss    = {} ## the dicts will be initialized in start_network\n",
    "        self.sample_loss    = {}\n",
    "        self.attempt_sample = []\n",
    "        self.success_sample = []\n",
    "        self.attempt_update = []\n",
    "        self.success_update = []\n",
    "        self.sample_time    = {} ## goes from 1 to MAX_STEPS inclusive in all cases\n",
    "        # self.prev_action_U  = None\n",
    "        # self.prev_action_S  = None\n",
    "        \n",
    "        \n",
    "        self.start_network(packet_update_loss, packet_sample_loss)\n",
    "        \n",
    "        # print(f\"sample_loss = {self.sample_loss}, update_loss = {self.update_loss}\")\n",
    "\n",
    "        self.action_space = Discrete(action_size)\n",
    "\n",
    "        self.observation_space =  Box(low=0.0, high=MAX_STEPS+1, shape=(2*(n_users)+1, 1), dtype=np.int)\n",
    "\n",
    "        self.state = np.concatenate((list([self.current_step]), [1]*2*(n_users)), axis=None) #\n",
    "\n",
    "        # if verbose:\n",
    "        # print(f\"initial state is {self._state} with length {np.shape(self._state)} when CSI_as_state = {CSI_as_state} and sample_error_in_CSI = {sample_error_in_CSI}\")  \n",
    "              \n",
    "        self._episode_ended = False\n",
    "        \n",
    "    def update_act_coverage(self):\n",
    "        ## remove the padding from the coverage 0s so that we get the actual coverage\n",
    "    \n",
    "        n = [i for i in list(self.users_UAVs.keys())] # UAV ids\n",
    "        k = [i for i in list(self.users_UAVs.values())] # all users\n",
    "        b = {} # this will be the act_coverage\n",
    "\n",
    "        for i in range(len(self.coverage)): # for each UAV ## don't make it UAV_list as it has not been made yet\n",
    "            old_list = self.users_UAVs[i] # users under UAV i\n",
    "            new_list = [j for j in old_list if j!=0] # 0s are padding not actual user. user ID cannot be 0, drone ID can be 0\n",
    "            b[i] = new_list\n",
    "\n",
    "        return b\n",
    "    \n",
    "    def start_network(self, packet_update_loss, packet_sample_loss):\n",
    "        \n",
    "        for i in range(len(self.coverage)): ## don't make it UAV_list as it has not been made yet\n",
    "            self.users_UAVs[i] = self.coverage[i]\n",
    "            # index of users_UAVs will start from 0\n",
    "            \n",
    "        self.act_coverage = self.update_act_coverage()\n",
    "        # print(f\"len act_coverage = {len(self.act_coverage)}\")   \n",
    "        self.user_list      = functools.reduce(operator.iconcat, list(self.act_coverage.values()), []) # list(self.act_coverage.values())\n",
    "        self.UAV_list       = list(self.act_coverage.keys())\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"user list = {self.user_list}\")\n",
    "            print(f\"UAV list  = {self.UAV_list}\")\n",
    "        \n",
    "        self.update_loss    = packet_update_loss\n",
    "        self.sample_loss    = packet_sample_loss\n",
    "        \n",
    "        for ii in self.user_list:\n",
    "            self.sample_time[ii] = []\n",
    "\n",
    "\n",
    "        if verbose:\n",
    "            print(f'self.n_users = {self.n_users}, self.n_UAVs = {self.n_UAVs}, self.act_coverage = {self.act_coverage}, self.update_loss = {self.update_loss}, self.sample_loss = {self.sample_loss}, self.UAV_list = {self.UAV_list}, self.user_list = {self.user_list}')\n",
    "            # time.sleep(15)\n",
    "\n",
    "        self.create_action_space()\n",
    "\n",
    "        # not doing in initialize_age() as initialize_age() is run every time net is reset so older values will be lost. start_network is run only once\n",
    "        for i in self.user_list:\n",
    "        \n",
    "            self.age_dist_UAV[i]   = [] # ending age of every episode, updated in _reset\n",
    "            self.age_dist_BS[i]    = []\n",
    "            \n",
    "            self.tx_attempt_BS[i]  = [] # number of attempts per episode, initialize in _reset and updated in _step\n",
    "            self.tx_attempt_UAV[i] = []   \n",
    "            \n",
    "        for i in range(self.action_size):\n",
    "            self.preference[i] = []\n",
    "            \n",
    "            \n",
    "        if verbose:\n",
    "            print(f'\\n{self.name} started and age_dist_UAV = {self.age_dist_UAV}, age_dist_BS = {self.age_dist_BS}, tx_attempt_BS = {self.tx_attempt_BS}, tx_attempt_UAV = {self.tx_attempt_UAV}\\n')\n",
    "\n",
    "    \n",
    "    def initialize_age(self):\n",
    "        \n",
    "        # before initializing, save the info    \n",
    "        # for the first time it is run, BS_age and others haven't even been initialized\n",
    "        \n",
    "        if self.episode_step!=1: ## why !=1 ??\n",
    "            \n",
    "            self.attempt_sample.append(0)\n",
    "            self.success_sample.append(0)\n",
    "            \n",
    "            self.attempt_update.append(0)\n",
    "            self.success_update.append(0)\n",
    "            \n",
    "            \n",
    "            for i in self.user_list:\n",
    "                \n",
    "                self.age_dist_UAV[i].append(self.UAV_age[i])\n",
    "                self.age_dist_BS[i].append(self.BS_age[i])\n",
    "                \n",
    "                self.tx_attempt_BS[i].append(0) # 0 will be changed in _step for every attempt\n",
    "                self.tx_attempt_UAV[i].append(0)\n",
    "                \n",
    "            for i in range(self.action_size):\n",
    "                self.preference[i].append(0) \n",
    "            \n",
    "            if verbose:\n",
    "                print(f'\\n{self.name} just before reset of {self.name} the age at UAV = {self.UAV_age}, age at BS = {self.BS_age} and these have used to update age_dist_UAV = {self.age_dist_UAV} and age_dist_BS = {self.age_dist_BS}\\n')\n",
    "                print(f'\\n{self.name} in the same reset block, tx_attempts have been updated as tx_attempt_UAV = {self.tx_attempt_UAV} and tx_attempt_BS = {self.tx_attempt_BS}\\n')\n",
    "                # print(f\"{self.name} preference is {self.preference}\")\n",
    "        \n",
    "        for i in self.user_list:\n",
    "            # initial age put 1 and not 0 as if 0, in first time step whethere sampled or not, all users age at UAV becomes 1 but for 1, it is different - 2 for not sampled and 1 for sampled\n",
    "            self.UAV_age[i] = 1\n",
    "            self.BS_age[i]  = 1\n",
    "            self.BS_age_prev[i] = 1 # special case for first step ??\n",
    "\n",
    "    def reset(self):\n",
    "        self.episode_step +=1\n",
    "        self.state = np.concatenate((list([self.current_step]), [1]*2*(len(self.user_list))), axis=None)\n",
    "            \n",
    "        self._episode_ended = False\n",
    "        self.current_step = 1\n",
    "        if verbose:\n",
    "            print(f'\\n{self.name} after reset, episode {self.episode_step} begins with self.state = {self.state} with shape {np.shape(self.state)}\\n') \n",
    "\n",
    "        self.initialize_age()\n",
    "        return self.state\n",
    "\n",
    "        \n",
    "    def map_actions(self, action):  \n",
    "        '''\n",
    "        convert the single integer action to specific sampling and updating tasks\n",
    "        '''\n",
    "        # print(f'inside  map_actions, action={action}, type(action)={type(action)}')\n",
    "        # print(f'action={action},self.actions_space={self.actions_space}')\n",
    "        actual_action = self.actions_space[action]\n",
    "        if verbose:\n",
    "            # print(f'action space is {self.actions_space}, length is {self.action_size}, array size is {len(self.actions_space)} selected action is {action} which maps to {actual_action}')\n",
    "            pass\n",
    "        return actual_action\n",
    "    \n",
    "    def get_current_state(self): # \n",
    "        state_UAV = np.array(list(self.UAV_age.values()))\n",
    "        state_BS  = np.array(list(self.BS_age.values()))\n",
    "        \n",
    "\n",
    "        self.state = np.concatenate((list([self.current_step]), state_UAV, state_BS), axis=None) \n",
    "\n",
    "        if verbose:\n",
    "            print(f'\\nself._state from of {self.name} get_current_state() = {self.state} with shape = {np.shape(self._state)}\\n') # debug\n",
    "        return (self.state)\n",
    "    \n",
    "    def create_action_space(self):\n",
    "        '''\n",
    "        for 1 UAV once the coverage has been decided, create the action space\n",
    "        2 data structures needed, a dict for storing sampling possibility at each UAV and a list to store the updating possibility\n",
    "        '''\n",
    "        \n",
    "        update_user_possibilities = []\n",
    "\n",
    "        if len(self.user_list) < self.BS_capacity: ## number of users available < number of users BS can update at anytime\n",
    "            update_user_possibilities = list(combinations(self.user_list, len(self.user_list)))\n",
    "        else:\n",
    "            update_user_possibilities = list(combinations(self.user_list, self.BS_capacity)) # different combination of selecting UAVs to update\n",
    "        if verbose:\n",
    "            print(f\"self.user_list = {self.user_list}, self.BS_capacity = {self.BS_capacity}, update_user_possibilities = {update_user_possibilities} with length {len(update_user_possibilities)}\")\n",
    "        \n",
    "        update_user_possibilities = [list(i) for i in update_user_possibilities]\n",
    "        \n",
    "        ## update action part done\n",
    "        sampling_choices = {}\n",
    "        ##a dict with all combinations of sampling UAV_capacity users from each UAV irrespective of which UAV got updated\n",
    "        for x in self.UAV_list:\n",
    "            sampling_choices[x] = []\n",
    "        \n",
    "        for k in self.UAV_list:\n",
    "            if len(self.act_coverage[k]) < self.UAV_capacity:\n",
    "                sampling_choices[k].extend(list(combinations(self.act_coverage[k], len(self.act_coverage[k]))))\n",
    "                # sampling_choices.extend(sampling_choice)\n",
    "                \n",
    "            else:\n",
    "                sampling_choice = list(combinations(self.act_coverage[k], self.UAV_capacity))\n",
    "                sampling_choices[k].extend(sampling_choice)\n",
    "                # if verbose:\n",
    "                #     print(f\"users covered under UAV k are {self.act_coverage[k]}, sampling_choice = {sampling_choice}, and sampling choices has become {sampling_choices}\")\n",
    "\n",
    "        all_user_sampling_combinations = []\n",
    "        for p in itertools.product(*sampling_choices.values()):\n",
    "            y = [yy for zz in p for yy in zz]\n",
    "            all_user_sampling_combinations.append(y)\n",
    "                   \n",
    "\n",
    "        actions_space = list(itertools.product(update_user_possibilities, all_user_sampling_combinations))\n",
    "        \n",
    "        actions_space = [list(i) for i in actions_space]\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\"sampling_choices = {sampling_choices} with length = {len(sampling_choices)} and \\nall_user_sampling_combinations is {all_user_sampling_combinations} with length {len(all_user_sampling_combinations)}\")\n",
    "            print(\"\\naction_size is \", len(actions_space)) #, \" and they are actions_space = \", actions_space)\n",
    "            # time.sleep(10)\n",
    "            \n",
    "            \n",
    "        self.actions_space = actions_space\n",
    "        self.action_size = len(self.actions_space)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{self.name} has a action_space of size \", np.shape(self.actions_space)) #, \" and they are \", self.actions_space,  \"\\n\")\n",
    "            # time.sleep(10)\n",
    "            \n",
    "        # print(\"\\n action_space is of size \", np.shape(self.actions_space), file = open(self.folder_name + \"/results.txt\", \"a\"))\n",
    "        # print(\"\\n action_space is of size \", np.shape(self.actions_space), \" and they are \", self.actions_space)\n",
    "    \n",
    "    def step(self, action):\n",
    "                  \n",
    "        if self._episode_ended:\n",
    "            if verbose:\n",
    "                print(f'for {self.name}, episode = {self.episode_step} at first reset')\n",
    "            return self.reset()\n",
    "        actual_action = self.map_actions(action)\n",
    "        print(f\"actual_action={actual_action}, action={action}\")\n",
    "        # action = action.tolist()\n",
    "\n",
    "        # print(f\"\\n env = {self.name}, self.current_step = {self.current_step}, self.episode_step = {self.episode_step}, action = {action}, type(action) = {type(action)}, (actual_action)={actual_action}, preference = {self.preference}\") #, {type(self.preference[action])}\") ## for some reason action is type nparray\n",
    "        # self.preference[action][-1] = self.preference[action][-1] + 1\n",
    "            \n",
    "        # updated_UAVs  = list(actual_action[0])\n",
    "        updated_users = list(actual_action[0])\n",
    "        # for j in updated_UAVs:\n",
    "        #     updated_users.extend(self.act_coverage[j])\n",
    "        sampled_users = list(actual_action[1])\n",
    "        if verbose:\n",
    "        \n",
    "            print(f'\\nfor {self.name}, current_step = {self.current_step}, selected action = {action}, actual_dqn_action={actual_action}, updated_users = {updated_users} sampled_users={sampled_users}\\n') \n",
    "            # time.sleep(3)\n",
    "            \n",
    "            print(f\"{self.name} tx_attempt_BS was {self.tx_attempt_BS}\")\n",
    "        \n",
    "        if self.current_step==1: ## updating\n",
    "        # step 1 so BS has nothing to get from UAV\n",
    "            for i in self.user_list:\n",
    "                self.BS_age[i] = self.BS_age[i]+1\n",
    "\n",
    "        else: # not time step = 1\n",
    "            for i in self.user_list: ## updating\n",
    "                if i in updated_users:\n",
    "                    ## find associated UAV\n",
    "                    for kk in self.act_coverage:\n",
    "                        if i in self.act_coverage[kk]:\n",
    "                            associated_UAV = kk\n",
    "                    ##\n",
    "                    self.tx_attempt_BS[i][-1] = self.tx_attempt_BS[i][-1] + 1\n",
    "                    self.attempt_update[-1] = self.attempt_update[-1] + 1\n",
    "                    chance_update_loss = np.round(random.random(), 2)\n",
    "                    if verbose:\n",
    "                    #     print(f\"user {i}'s associated UAV is {associated_UAV}\")\n",
    "                        print(f\"for user {i}, chance_update_loss = {chance_update_loss} and {self.name}.update_loss = {self.update_loss[i]} \")\n",
    "                    if chance_update_loss > self.update_loss[i]:\n",
    "                        if verbose:\n",
    "                            print(\"user \", i, \" was updated\")\n",
    "                        self.BS_age[i] = self.UAV_age[i] + 1 # age for the next slot, like how I update current_sample in my SWIFT work\n",
    "                        self.success_update[-1] = self.success_update[-1] + 1\n",
    "                    else:\n",
    "                        self.BS_age[i] = self.BS_age[i] + 1\n",
    "                        if verbose:\n",
    "                            print(f'user {i} was updated but had update failure')\n",
    "                            \n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(\"user \", i, \" was not updated\")\n",
    "                    self.BS_age[i] = self.BS_age[i] + 1\n",
    "                \n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{self.name} tx_attempt_BS has become {self.tx_attempt_BS}\")\n",
    "            ## for first step, even if some user was updated, it is not counted in the tx_attempt_BS as that tx has no role in minimizing AoI. Therefore for a scenario with 4 steps, tx_attempt_UAV will go to max 4 but tx_attempt_BS will go to 3 as only 3 attempts are counted\n",
    "            print(f\"{self.name} tx_attempt_UAV was {self.tx_attempt_UAV}\")\n",
    "\n",
    "        for i in self.user_list: ## sampling\n",
    "            if i in sampled_users:\n",
    "                self.sample_time[i].append(self.current_step)\n",
    "                chance_sample_loss = np.round(random.random(), 2)\n",
    "                self.tx_attempt_UAV[i][-1] = self.tx_attempt_UAV[i][-1] + 1\n",
    "                self.attempt_sample[-1] = self.attempt_sample[-1] + 1\n",
    "                if verbose:\n",
    "                    print(f\" for user {i}, chance_sample_loss = {chance_sample_loss} and self.sample_loss = {self.sample_loss[i]} \")\n",
    "                if chance_sample_loss > self.sample_loss[i]:\n",
    "                    if (self.current_step-1)%self.periodicity[i]==0: ## -1 as here time starts from 1\n",
    "                        if verbose:\n",
    "                            print(\"slot = \", self.current_step-1, \" - user \", i, \" period = \", self.periodicity[i], \" was selected to sample and sampled\")\n",
    "                        self.UAV_age[i] = 1 # age for the next slot, like how I update current_sample in my SWIFT work\n",
    "                        self.success_sample[-1] = self.success_sample[-1] + 1\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print(\"slot = \", self.current_step-1, \" - user \", i, \" period = \", self.periodicity[i], \" was selected to sample but not sampled\")                    \n",
    "                else:\n",
    "                    self.UAV_age[i] = self.UAV_age[i] + 1\n",
    "                    if verbose:\n",
    "                        print(f'user {i} was sampled but had sample failure')\n",
    "                        \n",
    "                    \n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\"user \", i, \" was not sampled\")\n",
    "                self.UAV_age[i] = self.UAV_age[i] + 1\n",
    "        \n",
    "        # print(f\"slot {self.current_step} ended with state {self._state}\")        \n",
    "                \n",
    "        if verbose:\n",
    "            print(f\"time = {self.current_step}, sample_time = {self.sample_time}\")\n",
    "            print(f\"{self.name} tx_attempt_UAV has become {self.tx_attempt_UAV}\")\n",
    "            # time.sleep(10)\n",
    "\n",
    "                \n",
    "        self._state = self.get_current_state() # update state after every action\n",
    "        \n",
    "       \n",
    "        BS_sum_age = np.sum(list(self.BS_age.values()))\n",
    "        \n",
    "        self.current_step += 1\n",
    "        \n",
    "        award = -BS_sum_age\n",
    "        \n",
    "        \n",
    "        # if verbose:\n",
    "        #     print(f\"attempt_sample = {self.attempt_sample}\")\n",
    "        #     print(f\"success_sample = {self.success_sample}\")\n",
    "        #     print(f\"attempt_update = {self.attempt_update}\")\n",
    "        #     print(f\"success_update = {self.success_update}\")\n",
    "        #     time.sleep(5)\n",
    "                   \n",
    "        \n",
    "        if verbose:\n",
    "            print(f'new current_step = {self.current_step}')\n",
    "            print(f\"{self.name} tx_attempt_UAV has become {self.tx_attempt_UAV}\")\n",
    "            print(f\"new state is {self.get_current_state()}\")\n",
    "            print(f'\\nfor {self.name}, award is {award}\\n') # debug\n",
    "            # time.sleep(10)\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        if self.current_step < MAX_STEPS + 1:        ## has to run for MAX_STEPS, i.e. an action has to be chosen MAX_STEPS times\n",
    "            done = False\n",
    "            return self.state, award, done, info\n",
    "        else:\n",
    "            # print(f'in terminate block') # will also reset the environment\n",
    "            done = True\n",
    "            # time_step.is_last() = True\n",
    "            return self.state, award, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "user list = [1, 2, 3]\nUAV list  = [0]\nself.n_users = 3, self.n_UAVs = 1, self.act_coverage = {0: [1, 2, 3]}, self.update_loss = {1: 0, 2: 0, 3: 0}, self.sample_loss = {1: 0, 2: 0, 3: 0}, self.UAV_list = [0], self.user_list = [1, 2, 3]\nself.user_list = [1, 2, 3], self.BS_capacity = 1, update_user_possibilities = [(1,), (2,), (3,)] with length 3\nsampling_choices = {0: [(1,), (2,), (3,)]} with length = 1 and \nall_user_sampling_combinations is [[1], [2], [3]] with length 3\n\naction_size is  9\n\nUAV_network has a action_space of size  (9, 2, 1)\n\nUAV_network started and age_dist_UAV = {1: [], 2: [], 3: []}, age_dist_BS = {1: [], 2: [], 3: []}, tx_attempt_BS = {1: [], 2: [], 3: []}, tx_attempt_UAV = {1: [], 2: [], 3: []}\n\n"
     ]
    }
   ],
   "source": [
    "env = UAV_network(3, {0:[1,2,3]}, \"UAV_network\", \"None\", {1:0,2:0,3:0}, {1:0,2:0,3:0}, {1:2,2:1,3:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [3],\n",
       "       [5],\n",
       "       [0],\n",
       "       [4],\n",
       "       [1],\n",
       "       [6]])"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nUAV_network after reset, episode 1 begins with self.state = [1 1 1 1 1 1 1] with shape (7,)\n\nactual_action=[[1], [1]], action=0\n\nfor UAV_network, current_step = 1, selected action = 0, actual_dqn_action=[[1], [1]], updated_users = [1] sampled_users=[1]\n\nUAV_network tx_attempt_BS was {1: [], 2: [], 3: []}\nUAV_network tx_attempt_BS has become {1: [], 2: [], 3: []}\nUAV_network tx_attempt_UAV was {1: [], 2: [], 3: []}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-1abe8e8c27a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#env.render()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mn_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mscore\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Episode:{} Score:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-a55523433d9e>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0mchance_sample_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtx_attempt_UAV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtx_attempt_UAV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattempt_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattempt_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        #env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# from create_graph_1 import *\n",
    "import pickle\n",
    "\n",
    "def running_mean(x): #, N = 5):\n",
    "    N = 100\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "\n",
    "path = \"/home/biplav/AoI/AoI-FL-UAV_ver1/runs/2021-11-20_02-51-01/\"\n",
    "path_RL = path + \"rl/\"\n",
    "path_FL = path + \"fl/\"\n",
    "\n",
    "\n",
    "rl_returns = pickle.load(open(path_RP + \"rl_returns.pickle\", \"rb\"))\n",
    "fl_returns = pickle.load(open(path_RP + \"fl_returns.pickle\", \"rb\"))\n",
    "\n",
    "final_round = \"24\"\n",
    "\n",
    "rl_returns = rl_returns[final_round]\n",
    "fl_returns = fl_returns[final_round]\n",
    "\n",
    "print(f\"rl_returns = {rl_returns}, fl_returns = {fl_returns}\")\n",
    "\n",
    "# fig, ax1 = plt.subplots()\n",
    "# ax1.plot(running_mean(dqn_8U_final), label = \"DQN\")\n",
    "# # ax1.plot(running_mean(dqn_8U_final_s2), marker = \"D\", label = \"DQN_s2\")\n",
    "# ax1.plot([-MAD_mean_8]*len(dqn_8U_final), label = \"MAD\")\n",
    "# ax1.plot([-random_mean_8]*len(dqn_8U_final), label = \"random\")\n",
    "# ax1.plot([-greedy_mean_8]*len(dqn_8U_final), label = \"greedy\")\n",
    "# ax1.legend()\n",
    "# ax1.tick_params(axis='x', labelsize=19)\n",
    "# ax1.tick_params(axis='y', labelsize=19)\n",
    "# legend = ax1.legend(loc='best', shadow=False, fontsize='19')\n",
    "\n",
    "\n",
    "\n",
    "# legend.get_frame().set_facecolor('0.90')\n",
    "# # ax1.set_title('8 users with 5 UAVs and $e$=0', fontsize='x-large')\n",
    "# plt.show\n",
    "# plt.xlabel('Iteration', fontsize='20')\n",
    "# plt.ylabel('Negative of sum of AoI at BS', fontsize='20')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "print(f\"MAD = {np.mean(MAD_8U_final[8])}, greedy = {np.mean(greedy_8U_final[8])}, DQN = {-np.mean(dqn_8U_final[-5:])}, random = {np.mean(random_8U_final[8])}\")"
   ]
  }
 ]
}